# -*- coding: utf-8 -*-
"""Statistics_app_002.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dXKlxA49KN11urPw60ECmFUi3ys8othS
"""

# # Install required packages
# !pip install streamlit
# !pip install seaborn
# !pip install plotly
# !pip install scipy
# !npm install localtunnel

# Save this as 'statistics_app.py'
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from scipy import stats
from sklearn.datasets import load_iris, load_wine, load_breast_cancer, load_diabetes
import warnings
import requests
warnings.filterwarnings('ignore')

# Set page configuration
st.set_page_config(
    page_title="Statistics Visualization Hub",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        background: linear-gradient(90deg, #1f77b4, #ff7f0e);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-weight: bold;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #2e86ab;
        margin: 1rem 0;
    }
    .highlight-box {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #1f77b4;
        margin: 1rem 0;
    }
    .metric-container {
        background-color: #ffffff;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
    }
    .clickable-section {
        background-color: #f8f9fa;
        padding: 1.5rem;
        margin: 1rem 0;
        border-radius: 10px;
        border: 2px solid #e9ecef;
        cursor: pointer;
        transition: all 0.3s ease;
    }
    .clickable-section:hover {
        border-color: #1f77b4;
        box-shadow: 0 4px 8px rgba(31, 119, 180, 0.2);
        transform: translateY(-2px);
    }
    .section-title {
        font-size: 1.3rem;
        font-weight: bold;
        color: #2e86ab;
        margin-bottom: 0.5rem;
    }
    .section-description {
        color: #6c757d;
        font-size: 0.95rem;
    }
    .navigation-buttons {
        display: flex;
        flex-wrap: wrap;
        gap: 1rem;
        justify-content: center;
        margin: 2rem 0;
    }
    .nav-button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem 1.5rem;
        border-radius: 10px;
        text-decoration: none;
        font-weight: bold;
        transition: all 0.3s ease;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .nav-button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.15);
    }
    .formula-box {
        background-color: #f8f9fa;
        border: 1px solid #dee2e6;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
        font-family: 'Courier New', monospace;
    }
    .definition-box {
        background-color: #e7f3ff;
        border-left: 4px solid #2196f3;
        padding: 1rem;
        margin: 1rem 0;
    }
    .simple-explanation {
        background-color: #fff3cd;
        border-left: 4px solid #ffc107;
        padding: 1rem;
        margin: 0.5rem 0;
        font-style: italic;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_sample_datasets():
    """Load and prepare sample datasets from sklearn"""
    datasets = {}

    # Iris dataset
    iris = load_iris()
    datasets['iris'] = pd.DataFrame(iris.data, columns=iris.feature_names)
    datasets['iris']['species'] = iris.target_names[iris.target]

    # Wine dataset
    wine = load_wine()
    datasets['wine'] = pd.DataFrame(wine.data, columns=wine.feature_names)
    datasets['wine']['wine_class'] = wine.target

    # Breast Cancer dataset
    cancer = load_breast_cancer()
    datasets['cancer'] = pd.DataFrame(cancer.data, columns=cancer.feature_names)
    datasets['cancer']['diagnosis'] = cancer.target_names[cancer.target]

    # Diabetes dataset
    diabetes = load_diabetes()
    datasets['diabetes'] = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)
    datasets['diabetes']['target'] = diabetes.target

    return datasets

def calculate_statistics(data):
    """Calculate comprehensive statistics for a dataset"""
    try:
        return {
            'mean': np.mean(data),
            'median': np.median(data),
            'mode': stats.mode(data, keepdims=True).mode[0] if len(data) > 0 else 'No mode',
            'std': np.std(data),
            'var': np.var(data),
            'range': np.max(data) - np.min(data),
            'q1': np.percentile(data, 25),
            'q3': np.percentile(data, 75),
            'iqr': np.percentile(data, 75) - np.percentile(data, 25),
            'cv': (np.std(data) / np.mean(data)) * 100 if np.mean(data) != 0 else 0
        }
    except Exception as e:
        st.error(f"Error calculating statistics: {str(e)}")
        return {}

def display_dora_gif():
    """Display Dora the Explorer inspired welcome message with animated GIF placeholder"""
    st.markdown("""
    <div style="text-align: center; margin: 2rem 0;">
        <div style="background: linear-gradient(135deg, #ff6b6b, #4ecdc4);
                    color: white; padding: 2rem; border-radius: 20px;
                    box-shadow: 0 8px 16px rgba(0,0,0,0.2);">
            <h2 style="margin: 0; font-size: 2rem;">üéí Looking for Learning? It Starts Here! üåü</h2>
            <p style="margin: 1rem 0; font-size: 1.2rem;">¬°Vamos! Let's explore the amazing world of statistics together!</p>
            <div style="font-size: 3rem; margin: 1rem 0;">üìäüîçüìà</div>
        </div>
    </div>
    """, unsafe_allow_html=True)

def create_navigation_buttons():
    """Create interactive navigation buttons"""
    sections = [
        ("üìà Descriptive Statistics", "descriptive"),
        ("üîç Data Types Explorer", "data_types"),
        ("üìê Central Tendency", "central_tendency"),
        ("üìè Dispersion Measures", "dispersion"),
        ("üìä Univariate Analysis", "univariate"),
        ("üîó Bivariate Analysis", "bivariate"),
        ("üìà Quantiles & Percentiles", "quantiles"),
        ("üìö Statistical Terminology", "terminology"),
        ("üí¨ Feedback", "feedback")
    ]

    st.markdown("### üéØ Choose Your Learning Journey")

    for i in range(0, len(sections), 3):
        cols = st.columns(3)
        for j, (title, key) in enumerate(sections[i:i+3]):
            if j < len(cols):
                with cols[j]:
                    if st.button(title, key=f"nav_{key}", use_container_width=True):
                        st.session_state.current_section = key
                        st.rerun()

def main():
    # Initialize session state
    if 'current_section' not in st.session_state:
        st.session_state.current_section = 'home'

    # Main content based on current section
    if st.session_state.current_section == 'home':
        show_home_page()
    elif st.session_state.current_section == 'descriptive':
        show_descriptive_stats()
    elif st.session_state.current_section == 'data_types':
        show_data_types()
    elif st.session_state.current_section == 'central_tendency':
        show_central_tendency()
    elif st.session_state.current_section == 'dispersion':
        show_dispersion()
    elif st.session_state.current_section == 'univariate':
        show_univariate_analysis()
    elif st.session_state.current_section == 'bivariate':
        show_bivariate_analysis()
    elif st.session_state.current_section == 'quantiles':
        show_quantiles()
    elif st.session_state.current_section == 'terminology':
        show_terminology()
    elif st.session_state.current_section == 'feedback':
        show_feedback_form()

def show_home_page():
    st.markdown('<h1 class="main-header">Statistics Visualization Hub</h1>', unsafe_allow_html=True)

    # Display Dora-inspired welcome message
    display_dora_gif()

    st.markdown("""
    <div class="highlight-box">
        <h2>üöÄ Welcome to the Interactive Statistics Learning Platform</h2>
        <p>Discover the power of statistics through real-world examples and interactive visualizations.
        Statistics drives billions of dollars in business decisions and shapes critical research worldwide.</p>
    </div>
    """, unsafe_allow_html=True)

    # High-impact statistics examples
    st.markdown("## üí∞ Statistics in Action: Real-World Impact")

    impact_examples = [
        ("üí∞ Business Intelligence", [
            "**$35B+** - Amazon's recommendation revenue annually",
            "**10-20 hours** saved daily by HelloFresh through analytics",
            "**Marketing ROI** improvements generating millions in revenue",
            "**A/B testing** increases conversion rates by 20-30%"
        ]),
        ("üè• Healthcare Revolution", [
            "**$200B+** - Annual pharmaceutical research budget",
            "**Clinical trials** save millions of lives worldwide",
            "**COVID-19 modeling** influenced trillion-dollar policies",
            "**Personalized medicine** improves treatment success rates"
        ]),
        ("üìä Financial Markets", [
            "**$100T+** - Global assets managed using statistical models",
            "**$6T+** - Insurance premiums based on risk statistics",
            "**High-frequency trading** generates billions through algorithms",
            "**Credit scoring** affects millions of loan decisions daily"
        ]),
        ("üèÜ Sports Analytics", [
            "**Multi-billion** dollar sports analytics industry",
            "**Player performance** optimization saves teams millions",
            "**Draft strategies** based on statistical player analysis",
            "**Injury prevention** through statistical health monitoring"
        ])
    ]

    cols = st.columns(2)
    for i, (title, examples) in enumerate(impact_examples):
        with cols[i % 2]:
            st.markdown(f"""
            <div class="metric-container">
                <h3>{title}</h3>
                <ul>
                    {"".join([f"<li>{example}</li>" for example in examples])}
                </ul>
            </div>
            """, unsafe_allow_html=True)

    # Navigation buttons
    create_navigation_buttons()

    # Quick stats about the platform
    st.markdown("---")
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("üìä Datasets", "4+", delta="Real-world data")
    with col2:
        st.metric("üìà Visualizations", "20+", delta="Interactive plots")
    with col3:
        st.metric("üßÆ Statistical Measures", "15+", delta="Key concepts")
    with col4:
        st.metric("üéØ Learning Sections", "9", delta="Comprehensive coverage")

def show_data_types():
    st.markdown('<h1 class="main-header">üîç Data Types Explorer</h1>', unsafe_allow_html=True)

    if st.button("üè† Back to Home", key="back_data_types"):
        st.session_state.current_section = 'home'
        st.rerun()

    st.markdown("""
    ## Understanding Data Types

    Data types are the foundation of statistical analysis. Understanding them helps you choose the right analytical techniques and visualizations.
    """)

    # Enhanced data type tabs
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "üìä Quantitative Data",
        "üìù Qualitative Data",
        "üî¢ Discrete vs Continuous",
        "üìã Nominal vs Ordinal",
        "üî¨ Observational vs Experimental",
        "‚è∞ Time Series"
    ])

    with tab1:
        st.subheader("üìä Quantitative Data (Numerical)")

        st.markdown("""
        <div class="definition-box">
            <strong>Definition:</strong> Data that represents quantities and can be measured numerically.
            Mathematical operations (addition, subtraction, etc.) can be performed on this data.
        </div>

        <div class="simple-explanation">
            <strong>Simple Explanation:</strong> Think of quantitative data as anything you can count or measure -
            like your height, the temperature outside, or how much money you have.
        </div>
        """, unsafe_allow_html=True)

        # Generate sample quantitative data
        np.random.seed(42)
        sample_size = st.slider("Sample size:", 100, 2000, 1000, key="quant_sample")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            **Real-world examples:**
            - **Manufacturing:** Product weights, dimensions, defect rates
            - **Finance:** Stock prices, trading volumes, profit margins
            - **Healthcare:** Patient vital signs, test results, medication dosages
            - **Sports:** Player statistics, game scores, performance metrics
            - **Education:** Test scores, GPA, study hours
            """)

        with col2:
            # Manufacturing quality control example
            manufacturing_data = np.random.normal(100, 5, sample_size)
            fig, ax = plt.subplots(figsize=(8, 5))
            ax.hist(manufacturing_data, bins=30, alpha=0.7, color='lightblue', edgecolor='black')
            ax.axvline(np.mean(manufacturing_data), color='red', linestyle='--',
                      label=f'Mean: {np.mean(manufacturing_data):.2f}g')
            ax.set_title('Manufacturing: Product Weight Distribution')
            ax.set_xlabel('Weight (grams)')
            ax.set_ylabel('Frequency')
            ax.legend()
            st.pyplot(fig)

    with tab2:
        st.subheader("üìù Qualitative Data (Categorical)")

        st.markdown("""
        <div class="definition-box">
            <strong>Definition:</strong> Data that represents categories, groups, or characteristics that cannot be measured numerically.
            Used for labeling or describing attributes.
        </div>

        <div class="simple-explanation">
            <strong>Simple Explanation:</strong> Qualitative data describes qualities or characteristics -
            like your favorite color, the brand of your phone, or your satisfaction level.
        </div>
        """, unsafe_allow_html=True)

        # Sample categorical data
        categories = ['Excellent', 'Good', 'Fair', 'Poor']
        sample_size_qual = st.slider("Number of responses:", 100, 1000, 500, key="qual_sample")
        customer_satisfaction = np.random.choice(categories, sample_size_qual, p=[0.3, 0.4, 0.2, 0.1])

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            **Real-world examples:**
            - **Customer Feedback:** Excellent, Good, Fair, Poor
            - **Demographics:** Gender, Race, Education Level
            - **Business:** Department, Job Title, Product Category
            - **Geography:** Country, City, Region
            - **Preferences:** Brand loyalty, Political affiliation
            """)

        with col2:
            satisfaction_counts = pd.Series(customer_satisfaction).value_counts()
            fig, ax = plt.subplots(figsize=(8, 5))
            colors = ['#2ecc71', '#f1c40f', '#e67e22', '#e74c3c']
            satisfaction_counts.plot(kind='bar', ax=ax, color=colors)
            ax.set_title('Customer Satisfaction Survey Results')
            ax.set_xlabel('Rating')
            ax.set_ylabel('Count')
            ax.set_xticklabels(satisfaction_counts.index, rotation=45)

            # Add percentage labels on bars
            for i, v in enumerate(satisfaction_counts.values):
                ax.text(i, v + 5, f'{v/sample_size_qual*100:.1f}%', ha='center')

            st.pyplot(fig)

    with tab3:
        st.subheader("üî¢ Discrete vs Continuous Data")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            <div class="definition-box">
                <strong>Discrete Data:</strong> Can only take specific, countable values with gaps between them.
                Usually obtained by counting.
            </div>

            <div class="simple-explanation">
                <strong>Simple Explanation:</strong> Discrete data comes in whole numbers you can count -
                like the number of students in a class (you can't have 23.5 students!).
            </div>
            """, unsafe_allow_html=True)

            st.markdown("""
            **Examples:**
            - Number of children in a family
            - Number of cars sold
            - Dice roll outcomes
            - Number of books on a shelf
            - Customer complaints per day
            """)

            # Discrete data example
            discrete_data = np.random.poisson(3, 500)
            fig, ax = plt.subplots(figsize=(8, 4))
            ax.hist(discrete_data, bins=range(0, max(discrete_data)+2), alpha=0.7, color='lightcoral', edgecolor='black')
            ax.set_title('Discrete Data: Number of Daily Customer Calls')
            ax.set_xlabel('Number of Calls')
            ax.set_ylabel('Frequency')
            st.pyplot(fig)

        with col2:
            st.markdown("""
            <div class="definition-box">
                <strong>Continuous Data:</strong> Can take any value within a range, including decimal places.
                Usually obtained by measuring.
            </div>

            <div class="simple-explanation">
                <strong>Simple Explanation:</strong> Continuous data can be any number with decimals -
                like your height (you could be 5.7834 feet tall).
            </div>
            """, unsafe_allow_html=True)

            st.markdown("""
            **Examples:**
            - Height and weight
            - Temperature
            - Time duration
            - Distance traveled
            - Stock prices
            """)

            # Continuous data example
            continuous_data = np.random.normal(70, 10, 500)
            fig, ax = plt.subplots(figsize=(8, 4))
            ax.hist(continuous_data, bins=30, alpha=0.7, color='lightgreen', edgecolor='black')
            ax.set_title('Continuous Data: Student Heights (inches)')
            ax.set_xlabel('Height (inches)')
            ax.set_ylabel('Frequency')
            st.pyplot(fig)

    with tab4:
        st.subheader("üìã Nominal vs Ordinal Data")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            <div class="definition-box">
                <strong>Nominal Data:</strong> Categories with no inherent order or ranking.
                Categories are just different, not better or worse.
            </div>

            <div class="simple-explanation">
                <strong>Simple Explanation:</strong> Nominal data is like different flavors of ice cream -
                vanilla isn't "better" than chocolate, they're just different categories.
            </div>
            """, unsafe_allow_html=True)

            st.markdown("""
            **Examples:**
            - Eye color (Blue, Brown, Green)
            - Gender (Male, Female, Other)
            - Marital status (Single, Married, Divorced)
            - Blood type (A, B, AB, O)
            - Product categories (Electronics, Clothing, Books)
            """)

            # Nominal data visualization
            eye_colors = ['Brown', 'Blue', 'Green', 'Hazel', 'Gray']
            eye_color_counts = np.random.multinomial(400, [0.35, 0.25, 0.15, 0.20, 0.05])

            fig, ax = plt.subplots(figsize=(8, 4))
            colors = ['#8B4513', '#4169E1', '#228B22', '#CD853F', '#808080']
            bars = ax.bar(eye_colors, eye_color_counts, color=colors)
            ax.set_title('Nominal Data: Eye Color Distribution')
            ax.set_ylabel('Count')
            st.pyplot(fig)

        with col2:
            st.markdown("""
            <div class="definition-box">
                <strong>Ordinal Data:</strong> Categories with a meaningful order or ranking.
                You can say one category is "higher" or "better" than another.
            </div>

            <div class="simple-explanation">
                <strong>Simple Explanation:</strong> Ordinal data is like movie ratings - 5 stars is definitely
                better than 1 star, and there's a clear order from worst to best.
            </div>
            """, unsafe_allow_html=True)

            st.markdown("""
            **Examples:**
            - Education level (High School < Bachelor's < Master's < PhD)
            - Customer satisfaction (Poor < Fair < Good < Excellent)
            - Movie ratings (1 star < 2 stars < 3 stars < 4 stars < 5 stars)
            - Income brackets (Low < Medium < High)
            - Survey responses (Strongly Disagree < Disagree < Neutral < Agree < Strongly Agree)
            """)

            # Ordinal data visualization
            satisfaction_levels = ['Poor', 'Fair', 'Good', 'Very Good', 'Excellent']
            satisfaction_counts = [50, 100, 200, 250, 150]

            fig, ax = plt.subplots(figsize=(8, 4))
            colors = ['#e74c3c', '#e67e22', '#f1c40f', '#2ecc71', '#27ae60']
            bars = ax.bar(satisfaction_levels, satisfaction_counts, color=colors)
            ax.set_title('Ordinal Data: Customer Satisfaction Levels')
            ax.set_ylabel('Count')
            ax.set_xticklabels(satisfaction_levels, rotation=45)
            st.pyplot(fig)

    with tab5:
        st.subheader("üî¨ Observational vs Experimental Data")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            <div class="definition-box">
                <strong>Observational Data:</strong> Data collected by observing subjects without manipulating
                or controlling any variables. Researchers observe what naturally occurs.
            </div>

            <div class="simple-explanation">
                <strong>Simple Explanation:</strong> Like being a detective - you watch and record what happens
                naturally without interfering. Like observing how many people wear masks in a store.
            </div>
            """, unsafe_allow_html=True)

            st.markdown("""
            **Characteristics:**
            - No manipulation of variables
            - Cannot establish causation (only correlation)
            - Reflects real-world conditions
            - May have confounding variables

            **Examples:**
            - Survey responses about shopping habits
            - Medical records analysis
            - Social media behavior tracking
            - Weather pattern observations
            - Traffic flow studies
            """)

            st.markdown("""
            **Advantages:**
            - ‚úÖ Ethical (no manipulation)
            - ‚úÖ Real-world applicability
            - ‚úÖ Large sample sizes possible
            - ‚úÖ Cost-effective

            **Disadvantages:**
            - ‚ùå Cannot prove causation
            - ‚ùå Confounding variables
            - ‚ùå Less control over conditions
            """)

        with col2:
            st.markdown("""
            <div class="definition-box">
                <strong>Experimental Data:</strong> Data collected through controlled experiments where researchers
                manipulate one or more variables to observe their effects.
            </div>

            <div class="simple-explanation">
                <strong>Simple Explanation:</strong> Like a science experiment - you change one thing and see what happens.
                Like testing if a new medicine works by giving it to some patients and not others.
            </div>
            """, unsafe_allow_html=True)

            st.markdown("""
            **Characteristics:**
            - Deliberate manipulation of variables
            - Can establish causation
            - Control groups used
            - Random assignment of subjects

            **Examples:**
            - Clinical drug trials
            - A/B testing for websites
            - Educational intervention studies
            - Marketing campaign experiments
            - Laboratory experiments
            """)

            st.markdown("""
            **Advantages:**
            - ‚úÖ Can establish causation
            - ‚úÖ High internal validity
            - ‚úÖ Control over variables
            - ‚úÖ Reproducible results

            **Disadvantages:**
            - ‚ùå May be unethical
            - ‚ùå Artificial conditions
            - ‚ùå Expensive and time-consuming
            - ‚ùå Limited sample sizes
            """)

        # Comparison visualization
        st.markdown("### üìä Key Differences Summary")

        comparison_data = {
            'Aspect': ['Control over variables', 'Causation', 'Cost', 'Ethics', 'Real-world applicability'],
            'Observational': ['Low', 'Cannot establish', 'Low', 'High', 'High'],
            'Experimental': ['High', 'Can establish', 'High', 'May be limited', 'May be limited']
        }

        comparison_df = pd.DataFrame(comparison_data)
        st.table(comparison_df)

    with tab6:
        st.subheader("‚è∞ Time Series Data")

        st.markdown("""
        <div class="definition-box">
            <strong>Time Series Data:</strong> Data points collected or recorded at successive time intervals.
            The order of observations matters, and time is a crucial component.
        </div>

        <div class="simple-explanation">
            <strong>Simple Explanation:</strong> Time series data is like a diary of numbers - it shows how something
            changes over time, like tracking your daily steps or a company's monthly sales.
        </div>
        """, unsafe_allow_html=True)

        # Generate sample time series
        days = st.slider("Number of days to display:", 30, 365, 100, key="time_series_days")
        dates = pd.date_range('2023-01-01', periods=days, freq='D')

        # Create different time series patterns
        trend_type = st.selectbox("Select pattern type:",
                                 ["Upward Trend", "Seasonal Pattern", "Random Walk", "Cyclical Pattern"])

        if trend_type == "Upward Trend":
            # Sales growth
            base_sales = 1000
            growth_rate = 0.01
            noise = np.random.normal(0, 50, days)
            sales_data = [base_sales * (1 + growth_rate) ** i + noise[i] for i in range(days)]
            title = "Daily Sales Revenue (Upward Trend)"
            ylabel = "Sales ($)"

        elif trend_type == "Seasonal Pattern":
            # Temperature with seasonal variation
            base_temp = 60
            seasonal = 20 * np.sin(2 * np.pi * np.arange(days) / 365)
            noise = np.random.normal(0, 3, days)
            sales_data = base_temp + seasonal + noise
            title = "Daily Temperature (Seasonal Pattern)"
            ylabel = "Temperature (¬∞F)"

        elif trend_type == "Random Walk":
            # Stock price random walk
            sales_data = np.cumsum(np.random.randn(days)) + 100
            title = "Stock Price (Random Walk)"
            ylabel = "Price ($)"

        else:  # Cyclical Pattern
            # Business cycle
            cycle = 500 * np.sin(2 * np.pi * np.arange(days) / 60)
            trend = np.arange(days) * 2
            noise = np.random.normal(0, 100, days)
            sales_data = 2000 + cycle + trend + noise
            title = "Monthly Revenue (Cyclical Pattern)"
            ylabel = "Revenue ($)"

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            **Key Characteristics:**
            - **Temporal ordering:** Order of observations matters
            - **Trends:** Long-term increases or decreases
            - **Seasonality:** Regular patterns that repeat
            - **Cycles:** Irregular fluctuations
            - **Autocorrelation:** Current values depend on past values

            **Real-world examples:**
            - **Business:** Daily sales, quarterly profits
            - **Finance:** Stock prices, currency exchange rates
            - **Healthcare:** Patient vital signs over time
            - **Environment:** Temperature, rainfall patterns
            - **Technology:** Website traffic, app usage
            """)

        with col2:
            fig, ax = plt.subplots(figsize=(10, 5))
            ax.plot(dates, sales_data, linewidth=2, color='#2ecc71')
            ax.set_title(title)
            ax.set_xlabel('Date')
            ax.set_ylabel(ylabel)
            ax.grid(True, alpha=0.3)
            plt.xticks(rotation=45)
            st.pyplot(fig)

        # Time series components explanation
        st.markdown("### üìà Time Series Components")

        components_info = {
            'Component': ['Trend', 'Seasonality', 'Cyclical', 'Irregular (Noise)'],
            'Description': [
                'Long-term increase or decrease in data',
                'Regular, predictable patterns (daily, monthly, yearly)',
                'Fluctuations with no fixed period',
                'Random variation that cannot be explained'
            ],
            'Example': [
                'Population growth over decades',
                'Ice cream sales higher in summer',
                'Economic boom and bust cycles',
                'Unexpected events affecting sales'
            ]
        }

        components_df = pd.DataFrame(components_info)
        st.table(components_df)

def show_central_tendency():
    st.markdown('<h1 class="main-header">üìê Measures of Central Tendency</h1>', unsafe_allow_html=True)

    if st.button("üè† Back to Home", key="back_central"):
        st.session_state.current_section = 'home'
        st.rerun()

    # Interactive parameter controls
    st.sidebar.subheader("üéõÔ∏è Interactive Controls")
    distribution_type = st.sidebar.selectbox("Choose distribution type:",
                                           ["Normal", "Right Skewed", "Left Skewed", "Bimodal", "Uniform"])
    sample_size = st.sidebar.slider("Sample size:", 100, 2000, 500)

    # Generate data based on selection
    np.random.seed(42)
    if distribution_type == "Normal":
        data = np.random.normal(50, 15, sample_size)
        description = "Normal distribution: symmetric, bell-shaped"
    elif distribution_type == "Right Skewed":
        data = np.random.exponential(2, sample_size) * 10 + 20
        description = "Right skewed: tail extends to the right"
    elif distribution_type == "Left Skewed":
        data = 100 - np.random.exponential(2, sample_size) * 10
        description = "Left skewed: tail extends to the left"
    elif distribution_type == "Uniform":
        data = np.random.uniform(20, 80, sample_size)
        description = "Uniform distribution: all values equally likely"
    else:  # Bimodal
        data1 = np.random.normal(30, 8, sample_size//2)
        data2 = np.random.normal(70, 8, sample_size//2)
        data = np.concatenate([data1, data2])
        description = "Bimodal distribution: two peaks"

    # Calculate measures
    stats_dict = calculate_statistics(data)
    if not stats_dict:
        return

    mean_val = stats_dict['mean']
    median_val = stats_dict['median']
    mode_val = stats_dict['mode']

    st.markdown(f"**Distribution Type:** {distribution_type} - {description}")

    # Display measures with enhanced explanations
    st.markdown("## üìä Central Tendency Measures")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown(f"""
        <div class="definition-box">
            <h3>üìä Mean (Average): {mean_val:.2f}</h3>
            <strong>Formula:</strong> Œº = Œ£x / n
            <br><br>
            <strong>When to use:</strong> With symmetric data, no extreme outliers
            <br><br>
            <strong>Business Applications:</strong>
            <ul>
                <li>Salary negotiations and benchmarking</li>
                <li>Production target setting</li>
                <li>Budget planning and forecasting</li>
                <li>Performance bonus calculations</li>
            </ul>
        </div>

        <div class="simple-explanation">
            <strong>Simple Explanation:</strong> Add all numbers and divide by how many numbers you have.
            Like finding the average test score in your class.
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown(f"""
        <div class="definition-box">
            <h3>üéØ Median (Middle Value): {median_val:.2f}</h3>
            <strong>Formula:</strong> Middle value when data is sorted
            <br><br>
            <strong>When to use:</strong> With skewed data or when outliers are present
            <br><br>
            <strong>Business Applications:</strong>
            <ul>
                <li>Real estate pricing analysis</li>
                <li>Income and wage studies</li>
                <li>Government policy decisions</li>
                <li>Market research insights</li>
            </ul>
        </div>

        <div class="simple-explanation">
            <strong>Simple Explanation:</strong> Line up all numbers from smallest to largest and pick the middle one.
            Like finding the middle person's height when everyone stands in order.
        </div>
        """, unsafe_allow_html=True)

    with col3:
        st.markdown(f"""
        <div class="definition-box">
            <h3>üîÑ Mode (Most Common): {mode_val:.2f}</h3>
            <strong>Formula:</strong> Most frequently occurring value
            <br><br>
            <strong>When to use:</strong> With categorical data or to find most popular choice
            <br><br>
            <strong>Business Applications:</strong>
            <ul>
                <li>Inventory planning (most popular sizes)</li>
                <li>Product preference analysis</li>
                <li>Service optimization</li>
                <li>Customer behavior patterns</li>
            </ul>
        </div>

        <div class="simple-explanation">
            <strong>Simple Explanation:</strong> The number that appears most often.
            Like finding the most popular pizza topping ordered at a restaurant.
        </div>
        """, unsafe_allow_html=True)

    # Enhanced visualization with measures highlighted
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))

    # Main distribution plot
    ax1.hist(data, bins=30, alpha=0.7, color='lightblue', edgecolor='black', density=True)
    ax1.axvline(mean_val, color='red', linestyle='--', linewidth=3, label=f'Mean: {mean_val:.2f}')
    ax1.axvline(median_val, color='green', linestyle='--', linewidth=3, label=f'Median: {median_val:.2f}')
    ax1.axvline(mode_val, color='orange', linestyle='--', linewidth=3, label=f'Mode: {mode_val:.2f}')
    ax1.set_title(f'{distribution_type} Distribution - Central Tendency Measures', fontsize=14, fontweight='bold')
    ax1.set_xlabel('Values')
    ax1.set_ylabel('Density')
    ax1.legend(fontsize=12)
    ax1.grid(True, alpha=0.3)

    # Box plot for additional insight
    ax2.boxplot(data, vert=False, patch_artist=True,
                boxprops=dict(facecolor='lightcoral', alpha=0.7))
    ax2.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.2f}')
    ax2.axvline(median_val, color='green', linestyle='--', linewidth=2, label=f'Median: {median_val:.2f}')
    ax2.set_title('Box Plot View')
    ax2.set_xlabel('Values')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    st.pyplot(fig)

    # Interpretation guide
    st.markdown("## üîç Interpretation Guide")

    skewness = stats.skew(data)
    if abs(skewness) < 0.5:
        skew_interpretation = "approximately symmetric (mean ‚âà median ‚âà mode)"
        skew_advice = "Any measure of central tendency is appropriate"
    elif skewness > 0.5:
        skew_interpretation = "right-skewed (mean > median > mode)"
        skew_advice = "Median is preferred as it's less affected by outliers"
    else:
        skew_interpretation = "left-skewed (mean < median < mode)"
        skew_advice = "Median is preferred as it's less affected by outliers"

    st.markdown(f"""
    **Distribution Analysis:**
    - **Skewness:** {skewness:.3f} - This distribution is {skew_interpretation}
    - **Recommendation:** {skew_advice}
    - **Sample Size:** {sample_size} observations
    """)

    # Real-world case studies
    st.markdown("## üíº Real-World Case Studies")

    case_studies = {
        "Salary Analysis": {
            "scenario": "Tech company analyzing employee compensation",
            "mean_use": "Used for budget allocation and industry benchmarking",
            "median_use": "Preferred for internal equity discussions (less affected by executive compensation)",
            "mode_use": "Identifies the most common pay grade for HR planning",
            "impact": "Accurate salary analysis helps retain talent and maintain competitiveness, potentially saving millions in turnover costs"
        },
        "Customer Satisfaction": {
            "scenario": "E-commerce platform measuring customer experience",
            "mean_use": "Overall satisfaction score for performance dashboards",
            "median_use": "Better represents typical customer experience",
            "mode_use": "Most common rating helps identify service quality patterns",
            "impact": "Understanding customer satisfaction drives product improvements and increases customer lifetime value"
        },
        "Product Quality": {
            "scenario": "Manufacturing company monitoring product specifications",
            "mean_use": "Process control and quality assurance standards",
            "median_use": "Robust measure when occasional defects create outliers",
            "mode_use": "Most common specification helps optimize production settings",
            "impact": "Quality control prevents defects, saving costs and maintaining brand reputation"
        }
    }

    selected_case = st.selectbox("Choose a case study:", list(case_studies.keys()))
    case = case_studies[selected_case]

    st.markdown(f"""
    **Scenario:** {case['scenario']}

    - **Mean Application:** {case['mean_use']}
    - **Median Application:** {case['median_use']}
    - **Mode Application:** {case['mode_use']}

    **Business Impact:** {case['impact']}
    """)

def show_dispersion():
    st.markdown('<h1 class="main-header">üìè Measures of Dispersion</h1>', unsafe_allow_html=True)

    if st.button("üè† Back to Home", key="back_dispersion"):
        st.session_state.current_section = 'home'
        st.rerun()

    datasets = load_sample_datasets()

    # Dataset and column selection
    dataset_choice = st.selectbox("Choose a dataset:", list(datasets.keys()))
    selected_data = datasets[dataset_choice]
    numeric_cols = selected_data.select_dtypes(include=[np.number]).columns.tolist()
    selected_columns = st.multiselect("Select columns to compare:", numeric_cols, default=numeric_cols[:2])

    if selected_columns:
        st.subheader("üìä Dispersion Comparison")

        dispersion_data = []
        for col in selected_columns:
            data = selected_data[col].dropna()
            stats_dict = calculate_statistics(data)
            if stats_dict:
                dispersion_data.append({
                    'Column': col,
                    'Standard Deviation': stats_dict['std'],
                    'Variance': stats_dict['var'],
                    'Range': stats_dict['range'],
                    'IQR': stats_dict['iqr'],
                    'Coefficient of Variation (%)': stats_dict['cv']
                })

        if dispersion_data:
            dispersion_df = pd.DataFrame(dispersion_data)
            st.dataframe(dispersion_df.round(3))

            # Enhanced visualization
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))

            for i, col in enumerate(selected_columns[:4]):
                if i < len(selected_columns):
                    row, column = divmod(i, 2)
                    data = selected_data[col].dropna()

                    # Box plot with additional statistics
                    box_plot = axes[row, column].boxplot(data, patch_artist=True)
                    box_plot['boxes'][0].set_facecolor('lightblue')
                    axes[row, column].set_title(f'{col}')
                    axes[row, column].set_ylabel('Values')
                    axes[row, column].grid(True, alpha=0.3)

                    # Add mean line
                    mean_val = np.mean(data)
                    axes[row, column].axhline(mean_val, color='red', linestyle='--', alpha=0.7, label=f'Mean: {mean_val:.2f}')
                    axes[row, column].legend()

            plt.tight_layout()
            st.pyplot(fig)

    # Theoretical explanation with formulas
    st.markdown("## üìö Dispersion Measures Explained")

    measures_info = [
        {
            "name": "Range",
            "formula": "Range = Maximum - Minimum",
            "definition": "The difference between the highest and lowest values in a dataset.",
            "simple": "How spread out your data is from lowest to highest - like the difference between the tallest and shortest person in your class.",
            "pros": "Easy to calculate and understand",
            "cons": "Sensitive to outliers, doesn't show distribution shape",
            "use_cases": ["Quality control limits", "Price range analysis", "Performance bounds"]
        },
        {
            "name": "Variance",
            "formula": "œÉ¬≤ = Œ£(x - Œº)¬≤ / N",
            "definition": "The average of squared differences from the mean. Measures how far data points are from the mean.",
            "simple": "Shows how much your data points differ from the average - bigger variance means more scattered data.",
            "pros": "Uses all data points, mathematically useful",
            "cons": "Units are squared, hard to interpret directly",
            "use_cases": ["Portfolio risk analysis", "Quality control", "Process optimization"]
        },
        {
            "name": "Standard Deviation",
            "formula": "œÉ = ‚àö(Œ£(x - Œº)¬≤ / N)",
            "definition": "The square root of variance. Shows typical deviation from the mean in original units.",
            "simple": "Like variance but in the same units as your data - tells you how spread out your data typically is.",
            "pros": "Same units as data, widely understood",
            "cons": "Sensitive to outliers",
            "use_cases": ["Six Sigma quality control", "Risk assessment", "Performance evaluation"]
        },
        {
            "name": "Interquartile Range (IQR)",
            "formula": "IQR = Q3 - Q1",
            "definition": "The range of the middle 50% of data. Difference between 75th and 25th percentiles.",
            "simple": "The spread of the middle half of your data - ignores extreme values at the top and bottom.",
            "pros": "Robust to outliers, shows middle spread",
            "cons": "Ignores tail information",
            "use_cases": ["Outlier detection", "Robust statistics", "Data cleaning"]
        },
        {
            "name": "Coefficient of Variation",
            "formula": "CV = (œÉ / Œº) √ó 100%",
            "definition": "Standard deviation as a percentage of the mean. Allows comparison across different scales.",
            "simple": "Compares variability relative to the average - useful when comparing datasets with very different scales.",
            "pros": "Scale-independent, allows fair comparison",
            "cons": "Undefined when mean is zero",
            "use_cases": ["Risk-return analysis", "Process comparison", "Benchmarking"]
        }
    ]

    for measure in measures_info:
        with st.expander(f"üìä {measure['name']}"):
            col1, col2 = st.columns(2)

            with col1:
                st.markdown(f"""
                <div class="formula-box">
                    <strong>Formula:</strong> {measure['formula']}
                </div>

                <div class="definition-box">
                    <strong>Definition:</strong> {measure['definition']}
                </div>
                """, unsafe_allow_html=True)

            with col2:
                st.markdown(f"""
                <div class="simple-explanation">
                    <strong>Simple Explanation:</strong> {measure['simple']}
                </div>

                **Advantages:** {measure['pros']}

                **Disadvantages:** {measure['cons']}

                **Use Cases:**
                {chr(10).join([f"‚Ä¢ {case}" for case in measure['use_cases']])}
                """)

    # Real-world applications
    st.markdown("## üè≠ Industry Applications")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("""
        <div class="metric-container">
            <h3>üè≠ Manufacturing Quality Control</h3>
            <ul>
                <li><strong>Standard Deviation:</strong> Monitor consistency in production</li>
                <li><strong>Six Sigma:</strong> Requires products within ¬±3 standard deviations</li>
                <li><strong>Range:</strong> Set acceptable quality limits</li>
                <li><strong>Impact:</strong> Prevents defects, saves millions in recalls</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown("""
        <div class="metric-container">
            <h3>üìà Investment Risk Management</h3>
            <ul>
                <li><strong>Standard Deviation:</strong> Measure portfolio volatility</li>
                <li><strong>Variance:</strong> Calculate risk-adjusted returns</li>
                <li><strong>CV:</strong> Compare assets with different price ranges</li>
                <li><strong>Impact:</strong> Optimize risk-return trade-offs for billions in assets</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

    with col3:
        st.markdown("""
        <div class="metric-container">
            <h3>üöö Supply Chain Management</h3>
            <ul>
                <li><strong>Range:</strong> Plan for delivery time variations</li>
                <li><strong>IQR:</strong> Set realistic service level agreements</li>
                <li><strong>Standard Deviation:</strong> Buffer inventory planning</li>
                <li><strong>Impact:</strong> Reduce costs and improve customer satisfaction</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

def show_univariate_analysis():
    st.markdown('<h1 class="main-header">üìä Univariate Analysis</h1>', unsafe_allow_html=True)

    if st.button("üè† Back to Home", key="back_univariate"):
        st.session_state.current_section = 'home'
        st.rerun()

    datasets = load_sample_datasets()

    # User controls
    dataset_choice = st.selectbox("Choose a dataset:", list(datasets.keys()))
    selected_data = datasets[dataset_choice]

    # Column selection
    numeric_cols = selected_data.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = selected_data.select_dtypes(include=['object', 'category']).columns.tolist()

    analysis_type = st.radio("Select analysis type:", ["Numerical Variable", "Categorical Variable"])

    if analysis_type == "Numerical Variable" and numeric_cols:
        selected_column = st.selectbox("Select numerical column:", numeric_cols)
        data = selected_data[selected_column].dropna()

        # Interactive controls
        col1, col2 = st.columns(2)
        with col1:
            bins = st.slider("Number of bins:", 10, 50, 30)
        with col2:
            plot_type = st.selectbox("Plot type:", [
                "Histogram", "Density Plot", "Box Plot", "Violin Plot",
                "Q-Q Plot", "Strip Plot", "Rug Plot", "ECDF Plot"
            ])

        # Create enhanced visualizations
        fig, ax = plt.subplots(figsize=(12, 6))

        if plot_type == "Histogram":
            n, bins_used, patches = ax.hist(data, bins=bins, alpha=0.7, color='skyblue', edgecolor='black')
            ax.set_title(f'Histogram of {selected_column}')
            ax.set_xlabel(selected_column)
            ax.set_ylabel('Frequency')

            # Add mean and median lines
            mean_val = np.mean(data)
            median_val = np.median(data)
            ax.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.2f}')
            ax.axvline(median_val, color='green', linestyle='--', linewidth=2, label=f'Median: {median_val:.2f}')
            ax.legend()

        elif plot_type == "Density Plot":
            sns.histplot(data, kde=True, ax=ax, stat='density')
            ax.set_title(f'Density Plot of {selected_column}')

        elif plot_type == "Box Plot":
            box_plot = ax.boxplot(data, patch_artist=True)
            box_plot['boxes'][0].set_facecolor('lightcoral')
            ax.set_title(f'Box Plot of {selected_column}')
            ax.set_ylabel(selected_column)

        elif plot_type == "Violin Plot":
            parts = ax.violinplot(data, positions=[1], widths=[0.6])
            for pc in parts['bodies']:
                pc.set_facecolor('lightgreen')
                pc.set_alpha(0.7)
            ax.set_title(f'Violin Plot of {selected_column}')
            ax.set_ylabel(selected_column)

        elif plot_type == "Q-Q Plot":
            stats.probplot(data, dist="norm", plot=ax)
            ax.set_title(f'Q-Q Plot of {selected_column}')

        elif plot_type == "Strip Plot":
            y_pos = np.random.normal(0, 0.1, len(data))
            ax.scatter(data, y_pos, alpha=0.6, color='orange')
            ax.set_title(f'Strip Plot of {selected_column}')
            ax.set_xlabel(selected_column)
            ax.set_ylabel('Jittered Y')

        elif plot_type == "Rug Plot":
            ax.hist(data, bins=bins, alpha=0.7, color='lightblue', edgecolor='black')
            ax2 = ax.twinx()
            ax2.set_ylim(0, 1)
            for value in data[::max(1, len(data)//100)]:  # Sample for performance
                ax2.axvline(value, ymin=0, ymax=0.1, color='red', alpha=0.3)
            ax.set_title(f'Histogram with Rug Plot of {selected_column}')
            ax2.set_ylabel('Rug')

        else:  # ECDF Plot
            sorted_data = np.sort(data)
            y = np.arange(1, len(sorted_data) + 1) / len(sorted_data)
            ax.plot(sorted_data, y, marker='.', linestyle='none')
            ax.set_title(f'Empirical CDF of {selected_column}')
            ax.set_xlabel(selected_column)
            ax.set_ylabel('Cumulative Probability')
            ax.grid(True, alpha=0.3)

        ax.grid(True, alpha=0.3)
        st.pyplot(fig)

        # Enhanced distribution analysis
        st.subheader("üìà Distribution Analysis")

        stats_dict = calculate_statistics(data)
        if stats_dict:
            skewness = stats.skew(data)
            kurtosis = stats.kurtosis(data)

            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("Skewness", f"{skewness:.3f}")
                if skewness > 0.5:
                    st.write("üî¥ Right-skewed")
                elif skewness < -0.5:
                    st.write("üîµ Left-skewed")
                else:
                    st.write("üü¢ Approximately symmetric")

            with col2:
                st.metric("Kurtosis", f"{kurtosis:.3f}")
                if kurtosis > 0:
                    st.write("üìà Heavy-tailed")
                else:
                    st.write("üìâ Light-tailed")

            with col3:
                # Normality test
                _, p_value = stats.normaltest(data)
                st.metric("Normality p-value", f"{p_value:.4f}")
                if p_value > 0.05:
                    st.write("‚úÖ Likely normal")
                else:
                    st.write("‚ùå Not normal")

            with col4:
                # Outlier detection using IQR method
                Q1 = np.percentile(data, 25)
                Q3 = np.percentile(data, 75)
                IQR = Q3 - Q1
                outliers = data[(data < Q1 - 1.5 * IQR) | (data > Q3 + 1.5 * IQR)]
                st.metric("Outliers", len(outliers))
                st.write(f"({len(outliers)/len(data)*100:.1f}% of data)")

    elif analysis_type == "Categorical Variable" and categorical_cols:
        selected_column = st.selectbox("Select categorical column:", categorical_cols)
        data = selected_data[selected_column].value_counts()

        # Visualization options
        plot_type = st.selectbox("Plot type:", ["Bar Chart", "Horizontal Bar", "Pie Chart", "Donut Chart"])

        fig, ax = plt.subplots(figsize=(10, 6))

        if plot_type == "Bar Chart":
            bars = data.plot(kind='bar', ax=ax, color='lightcoral')
            ax.set_title(f'Bar Chart of {selected_column}')
            ax.set_ylabel('Count')
            plt.xticks(rotation=45)

            # Add value labels on bars
            for i, v in enumerate(data.values):
                ax.text(i, v + max(data.values) * 0.01, str(v), ha='center', va='bottom')

        elif plot_type == "Horizontal Bar":
            data.plot(kind='barh', ax=ax, color='lightgreen')
            ax.set_title(f'Horizontal Bar Chart of {selected_column}')
            ax.set_xlabel('Count')

        elif plot_type == "Pie Chart":
            wedges, texts, autotexts = ax.pie(data.values, labels=data.index, autopct='%1.1f%%')
            ax.set_title(f'Pie Chart of {selected_column}')

        else:  # Donut Chart
            wedges, texts, autotexts = ax.pie(data.values, labels=data.index, autopct='%1.1f%%')
            centre_circle = plt.Circle((0,0), 0.70, fc='white')
            ax.add_artist(centre_circle)
            ax.set_title(f'Donut Chart of {selected_column}')

        plt.tight_layout()
        st.pyplot(fig)

        # Categorical analysis
        st.subheader("üìä Categorical Analysis")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**Category Statistics:**")
            st.write(f"**Number of categories:** {len(data)}")
            st.write(f"**Most common:** {data.index[0]} ({data.iloc[0]} occurrences)")
            st.write(f"**Least common:** {data.index[-1]} ({data.iloc[-1]} occurrences)")
            st.write(f"**Total observations:** {data.sum()}")

        with col2:
            st.markdown("**Frequency Table:**")
            freq_table = pd.DataFrame({
                'Category': data.index,
                'Count': data.values,
                'Percentage': (data.values / data.sum() * 100).round(2)
            })
            st.dataframe(freq_table)

def show_bivariate_analysis():
    st.markdown('<h1 class="main-header">üîó Bivariate Analysis</h1>', unsafe_allow_html=True)

    if st.button("üè† Back to Home", key="back_bivariate"):
        st.session_state.current_section = 'home'
        st.rerun()

    st.markdown("""
    ## Understanding Bivariate Analysis

    Bivariate analysis examines the relationship between two variables. The type of analysis depends on
    the data types of both variables.
    """)

    datasets = load_sample_datasets()

    # Dataset selection
    dataset_choice = st.selectbox("Choose a dataset:", list(datasets.keys()))
    selected_data = datasets[dataset_choice]

    # Variable selection
    numeric_cols = selected_data.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = selected_data.select_dtypes(include=['object', 'category']).columns.tolist()

    analysis_type = st.selectbox("Select relationship type:",
                                ["Numerical vs Numerical", "Categorical vs Numerical", "Categorical vs Categorical"])

    if analysis_type == "Numerical vs Numerical" and len(numeric_cols) >= 2:
        st.subheader("üìä Numerical vs Numerical Analysis")

        st.markdown("""
        <div class="definition-box">
            <strong>What it means:</strong> Analyzing the relationship between two continuous variables to understand
            how they change together. This helps identify patterns, trends, and correlations.
        </div>

        <div class="simple-explanation">
            <strong>Simple Explanation:</strong> Like checking if taller people tend to weigh more,
            or if students who study more hours get better grades.
        </div>
        """, unsafe_allow_html=True)

        col1, col2 = st.columns(2)
        with col1:
            x_var = st.selectbox("Select X variable:", numeric_cols, key="x_var_num")
        with col2:
            y_var = st.selectbox("Select Y variable:", [col for col in numeric_cols if col != x_var], key="y_var_num")

        # Create enhanced scatter plot
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

        x_data = selected_data[x_var].dropna()
        y_data = selected_data[y_var].dropna()

        # Ensure same length
        min_len = min(len(x_data), len(y_data))
        if min_len > 0:
            x_data = x_data.iloc[:min_len]
            y_data = y_data.iloc[:min_len]

            # Scatter plot with regression line
            ax1.scatter(x_data, y_data, alpha=0.6, color='blue')

            # Add regression line
            try:
                z = np.polyfit(x_data, y_data, 1)
                p = np.poly1d(z)
                ax1.plot(x_data, p(x_data), "r--", alpha=0.8, linewidth=2)
                ax1.set_xlabel(x_var)
                ax1.set_ylabel(y_var)
                ax1.set_title(f'Scatter Plot: {x_var} vs {y_var}')
                ax1.grid(True, alpha=0.3)

                # Correlation analysis
                correlation = np.corrcoef(x_data, y_data)[0, 1]

                # Hexbin plot for density
                hb = ax2.hexbin(x_data, y_data, gridsize=20, cmap='Blues')
                ax2.set_xlabel(x_var)
                ax2.set_ylabel(y_var)
                ax2.set_title(f'Density Plot: {x_var} vs {y_var}')
                plt.colorbar(hb, ax=ax2)

                plt.tight_layout()
                st.pyplot(fig)

                # Correlation interpretation
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric("Pearson Correlation", f"{correlation:.3f}")

                with col2:
                    if abs(correlation) > 0.7:
                        strength = "Strong"
                        color = "üî¥"
                    elif abs(correlation) > 0.3:
                        strength = "Moderate"
                        color = "üü°"
                    else:
                        strength = "Weak"
                        color = "üü¢"
                    st.write(f"{color} {strength} correlation")

                with col3:
                    direction = "Positive" if correlation > 0 else "Negative"
                    st.write(f"üìà {direction} relationship")

                # Interpretation guide
                st.markdown("### üîç Interpretation:")
                if correlation > 0.7:
                    interpretation = f"Strong positive relationship: As {x_var} increases, {y_var} tends to increase significantly."
                elif correlation > 0.3:
                    interpretation = f"Moderate positive relationship: As {x_var} increases, {y_var} tends to increase somewhat."
                elif correlation > -0.3:
                    interpretation = f"Weak relationship: {x_var} and {y_var} don't show a clear linear relationship."
                elif correlation > -0.7:
                    interpretation = f"Moderate negative relationship: As {x_var} increases, {y_var} tends to decrease somewhat."
                else:
                    interpretation = f"Strong negative relationship: As {x_var} increases, {y_var} tends to decrease significantly."

                st.write(interpretation)

            except Exception as e:
                st.error(f"Error in analysis: {str(e)}")

    elif analysis_type == "Categorical vs Numerical":
        st.subheader("üìä Categorical vs Numerical Analysis")

        st.markdown("""
        <div class="definition-box">
            <strong>What it means:</strong> Comparing numerical values across different categories to understand
            how categories differ in terms of the numerical variable.
        </div>

        <div class="simple-explanation">
            <strong>Simple Explanation:</strong> Like comparing average salaries across different departments,
            or test scores between different schools.
        </div>
        """, unsafe_allow_html=True)

        if categorical_cols and numeric_cols:
            col1, col2 = st.columns(2)
            with col1:
                cat_var = st.selectbox("Select categorical variable:", categorical_cols, key="cat_var")
            with col2:
                num_var = st.selectbox("Select numerical variable:", numeric_cols, key="num_var")

            # Enhanced visualizations
            plot_choice = st.selectbox("Choose visualization:",
                                     ["Box Plot", "Violin Plot", "Strip Plot", "Bar Plot", "Swarm Plot"])

            fig, ax = plt.subplots(figsize=(12, 6))

            try:
                if plot_choice == "Box Plot":
                    sns.boxplot(data=selected_data, x=cat_var, y=num_var, ax=ax)
                    ax.set_title(f'Box Plot: {num_var} by {cat_var}')

                elif plot_choice == "Violin Plot":
                    sns.violinplot(data=selected_data, x=cat_var, y=num_var, ax=ax)
                    ax.set_title(f'Violin Plot: {num_var} by {cat_var}')

                elif plot_choice == "Strip Plot":
                    sns.stripplot(data=selected_data, x=cat_var, y=num_var, ax=ax, alpha=0.7)
                    ax.set_title(f'Strip Plot: {num_var} by {cat_var}')

                elif plot_choice == "Bar Plot":
                    sns.barplot(data=selected_data, x=cat_var, y=num_var, ax=ax)
                    ax.set_title(f'Bar Plot: Average {num_var} by {cat_var}')

                else:  # Swarm Plot
                    if len(selected_data) < 1000:  # Swarm plot works better with smaller datasets
                        sns.swarmplot(data=selected_data, x=cat_var, y=num_var, ax=ax)
                        ax.set_title(f'Swarm Plot: {num_var} by {cat_var}')
                    else:
                        sns.stripplot(data=selected_data, x=cat_var, y=num_var, ax=ax, alpha=0.7)
                        ax.set_title(f'Strip Plot: {num_var} by {cat_var} (Swarm not suitable for large data)')

                plt.xticks(rotation=45)
                plt.tight_layout()
                st.pyplot(fig)

                # Group statistics
                group_stats = selected_data.groupby(cat_var)[num_var].agg(['count', 'mean', 'std', 'min', 'max']).round(3)
                st.subheader("üìä Group Statistics")
                st.dataframe(group_stats)

                # Statistical test
                groups = [group[num_var].dropna() for name, group in selected_data.groupby(cat_var)]
                if len(groups) >= 2 and all(len(group) > 1 for group in groups):
                    if len(groups) == 2:
                        statistic, p_value = stats.ttest_ind(groups[0], groups[1])
                        test_name = "T-test"
                    else:
                        statistic, p_value = stats.f_oneway(*groups)
                        test_name = "ANOVA"

                    st.subheader(f"üìà Statistical Test ({test_name})")
                    col1, col2 = st.columns(2)

                    with col1:
                        st.metric("Test Statistic", f"{statistic:.4f}")
                    with col2:
                        st.metric("P-value", f"{p_value:.4f}")

                    if p_value < 0.05:
                        st.write("‚úÖ **Significant difference** between groups (p < 0.05)")
                    else:
                        st.write("‚ùå **No significant difference** between groups (p ‚â• 0.05)")

            except Exception as e:
                st.error(f"Error creating visualization: {str(e)}")

    elif analysis_type == "Categorical vs Categorical":
        st.subheader("üìä Categorical vs Categorical Analysis")

        st.markdown("""
        <div class="definition-box">
            <strong>What it means:</strong> Examining the relationship between two categorical variables to understand
            if they are independent or if there's an association between them.
        </div>

        <div class="simple-explanation">
            <strong>Simple Explanation:</strong> Like checking if gender is related to preferred movie genre,
            or if education level is associated with political preference.
        </div>
        """, unsafe_allow_html=True)

        if len(categorical_cols) >= 2:
            col1, col2 = st.columns(2)
            with col1:
                cat_var1 = st.selectbox("Select first categorical variable:", categorical_cols, key="cat1")
            with col2:
                cat_var2 = st.selectbox("Select second categorical variable:",
                                       [col for col in categorical_cols if col != cat_var1], key="cat2")

            # Cross-tabulation
            try:
                crosstab = pd.crosstab(selected_data[cat_var1], selected_data[cat_var2])

                st.subheader("üìã Cross-tabulation Table")
                st.dataframe(crosstab)

                # Enhanced visualizations
                plot_choice = st.selectbox("Choose visualization:",
                                         ["Heatmap", "Stacked Bar", "Grouped Bar", "Mosaic Plot"])

                fig, ax = plt.subplots(figsize=(12, 6))

                if plot_choice == "Heatmap":
                    sns.heatmap(crosstab, annot=True, fmt='d', cmap='Blues', ax=ax)
                    ax.set_title(f'Heatmap: {cat_var1} vs {cat_var2}')

                elif plot_choice == "Stacked Bar":
                    crosstab.plot(kind='bar', stacked=True, ax=ax)
                    ax.set_title(f'Stacked Bar Chart: {cat_var1} vs {cat_var2}')
                    ax.legend(title=cat_var2, bbox_to_anchor=(1.05, 1), loc='upper left')

                elif plot_choice == "Grouped Bar":
                    crosstab.plot(kind='bar', ax=ax)
                    ax.set_title(f'Grouped Bar Chart: {cat_var1} vs {cat_var2}')
                    ax.legend(title=cat_var2, bbox_to_anchor=(1.05, 1), loc='upper left')

                else:  # Mosaic Plot (simplified version)
                    # Create a simplified mosaic-like visualization
                    proportions = crosstab.div(crosstab.sum(axis=1), axis=0)
                    sns.heatmap(proportions, annot=True, fmt='.2f', cmap='YlOrRd', ax=ax)
                    ax.set_title(f'Proportion Heatmap: {cat_var1} vs {cat_var2}')

                plt.xticks(rotation=45)
                plt.tight_layout()
                st.pyplot(fig)

                # Chi-square test
                chi2, p_value, dof, expected = stats.chi2_contingency(crosstab)

                st.subheader("üìà Chi-Square Test for Independence")

                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric("Chi-Square Statistic", f"{chi2:.4f}")
                with col2:
                    st.metric("P-value", f"{p_value:.4f}")
                with col3:
                    st.metric("Degrees of Freedom", dof)

                if p_value < 0.05:
                    st.write("‚úÖ **Significant association** between variables (p < 0.05)")
                    st.write("The two variables are not independent.")
                else:
                    st.write("‚ùå **No significant association** between variables (p ‚â• 0.05)")
                    st.write("The two variables appear to be independent.")

                # Cram√©r's V for effect size
                n = crosstab.sum().sum()
                cramers_v = np.sqrt(chi2 / (n * (min(crosstab.shape) - 1)))
                st.metric("Cram√©r's V (Effect Size)", f"{cramers_v:.4f}")

                if cramers_v < 0.1:
                    effect_size = "Negligible"
                elif cramers_v < 0.3:
                    effect_size = "Small"
                elif cramers_v < 0.5:
                    effect_size = "Medium"
                else:
                    effect_size = "Large"

                st.write(f"Effect size: **{effect_size}**")

            except Exception as e:
                st.error(f"Error in categorical analysis: {str(e)}")

def show_quantiles():
    st.markdown('<h1 class="main-header">üìà Quantiles & Percentiles</h1>', unsafe_allow_html=True)

    if st.button("üè† Back to Home", key="back_quantiles"):
        st.session_state.current_section = 'home'
        st.rerun()

    st.markdown("""
    ## Understanding Quantiles and Percentiles

    Quantiles divide a dataset into equal parts, helping us understand the distribution and position of values.
    """)

    # Generate sample data
    np.random.seed(42)
    sample_size = st.slider("Sample size:", 100, 1000, 500)
    distribution_type = st.selectbox("Distribution type:", ["Normal", "Exponential", "Uniform", "Beta"])

    if distribution_type == "Normal":
        data = np.random.normal(50, 15, sample_size)
    elif distribution_type == "Exponential":
        data = np.random.exponential(2, sample_size) * 10 + 20
    elif distribution_type == "Uniform":
        data = np.random.uniform(10, 90, sample_size)
    else:  # Beta
        data = np.random.beta(2, 5, sample_size) * 100

    # Calculate quantiles
    quartiles = [np.percentile(data, q) for q in [25, 50, 75]]
    deciles = [np.percentile(data, q) for q in range(10, 100, 10)]
    quintiles = [np.percentile(data, q) for q in [20, 40, 60, 80]]

    # Enhanced quantile information with formulas
    st.markdown("## üìä Quantile Types and Formulas")

    quantile_tabs = st.tabs(["üìä Quartiles", "üîü Deciles", "üéØ Quintiles", "üìà Percentiles"])

    with quantile_tabs[0]:
        st.subheader("üìä Quartiles")

        st.markdown("""
        <div class="definition-box">
            <strong>Definition:</strong> Quartiles divide data into four equal parts. Each part contains 25% of the data.
        </div>

        <div class="formula-box">
            <strong>Formulas:</strong><br>
            Q1 = P25 (25th percentile)<br>
            Q2 = P50 (50th percentile = Median)<br>
            Q3 = P75 (75th percentile)<br>
            IQR = Q3 - Q1 (Interquartile Range)
        </div>

        <div class="simple-explanation">
            <strong>Simple Explanation:</strong> Imagine lining up all students by test score.
            Quartiles tell you the scores that separate the bottom 25%, middle 50%, and top 25%.
        </div>
        """, unsafe_allow_html=True)

        col1, col2 = st.columns(2)

        with col1:
            for i, q in enumerate(quartiles, 1):
                st.write(f"**Q{i} ({i*25}th percentile):** {q:.2f}")
            st.write(f"**IQR:** {quartiles[2] - quartiles[0]:.2f}")

            st.markdown("""
            **Business Applications:**
            - **Performance quartiles** for employee evaluation
            - **Customer segmentation** by purchase value
            - **Quality control** using quartile ranges
            - **Risk assessment** in finance
            """)

        with col2:
            fig, ax = plt.subplots(figsize=(8, 5))
            ax.hist(data, bins=30, alpha=0.7, color='lightblue', edgecolor='black')

            colors = ['red', 'orange', 'green']
            for i, q in enumerate(quartiles):
                ax.axvline(q, color=colors[i], linestyle='--', linewidth=2,
                          label=f'Q{i+1}: {q:.2f}')

            ax.set_title('Distribution with Quartile Lines')
            ax.set_xlabel('Values')
            ax.set_ylabel('Frequency')
            ax.legend()
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)

    with quantile_tabs[1]:
        st.subheader("üîü Deciles")

        st.markdown("""
        <div class="definition-box">
            <strong>Definition:</strong> Deciles divide data into ten equal parts. Each part contains 10% of the data.
        </div>

        <div class="formula-box">
            <strong>Formula:</strong><br>
            Di = P(i√ó10) where i = 1, 2, ..., 9<br>
            Example: D1 = P10, D5 = P50, D9 = P90
        </div>

        <div class="simple-explanation">
            <strong>Simple Explanation:</strong> Like dividing a pizza into 10 equal slices.
            Deciles tell you the values that mark each slice boundary.
        </div>
        """, unsafe_allow_html=True)

        col1, col2 = st.columns(2)

        with col1:
            for i, decile in enumerate(deciles, 1):
                st.write(f"**D{i} ({i*10}th percentile):** {decile:.2f}")

            st.markdown("""
            **Business Applications:**
            - **Customer lifetime value** ranking
            - **Sales performance** evaluation
            - **Market research** segmentation
            - **Academic grading** systems
            """)

        with col2:
            fig, ax = plt.subplots(figsize=(8, 5))
            ax.hist(data, bins=30, alpha=0.7, color='lightyellow', edgecolor='black')

            for i, d in enumerate(deciles[::2]):  # Show every other decile for clarity
                ax.axvline(d, color='purple', linestyle=':', alpha=0.7,
                          label=f'D{(i*2)+1}: {d:.1f}')

            ax.set_title('Distribution with Selected Decile Lines')
            ax.set_xlabel('Values')
            ax.set_ylabel('Frequency')
            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)

    with quantile_tabs[2]:
        st.subheader("üéØ Quintiles")

        st.markdown("""
        <div class="definition-box">
            <strong>Definition:</strong> Quintiles divide data into five equal parts. Each part contains 20% of the data.
        </div>

        <div class="formula-box">
            <strong>Formula:</strong><br>
            Qi = P(i√ó20) where i = 1, 2, 3, 4<br>
            Example: Q1 = P20, Q2 = P40, Q3 = P60, Q4 = P80
        </div>

        <div class="simple-explanation">
            <strong>Simple Explanation:</strong> Like dividing your class into 5 equal groups based on grades.
            Each group has the same number of students.
        </div>
        """, unsafe_allow_html=True)

        col1, col2 = st.columns(2)

        with col1:
            for i, quintile in enumerate(quintiles, 1):
                st.write(f"**Quintile {i} ({i*20}th percentile):** {quintile:.2f}")

            st.markdown("""
            **Business Applications:**
            - **Investment portfolio** risk categories
            - **Insurance premium** calculations
            - **Market share** analysis
            - **Product rating** systems
            """)

        with col2:
            fig, ax = plt.subplots(figsize=(8, 5))
            ax.hist(data, bins=30, alpha=0.7, color='lightcoral', edgecolor='black')

            colors = ['blue', 'green', 'orange', 'red']
            for i, q in enumerate(quintiles):
                ax.axvline(q, color=colors[i], linestyle='--', linewidth=2,
                          label=f'Q{i+1}: {q:.2f}')

            ax.set_title('Distribution with Quintile Lines')
            ax.set_xlabel('Values')
            ax.set_ylabel('Frequency')
            ax.legend()
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)

    with quantile_tabs[3]:
        st.subheader("üìà Percentiles")

        st.markdown("""
        <div class="definition-box">
            <strong>Definition:</strong> Percentiles divide data into 100 equal parts. The kth percentile is the value below which k% of data falls.
        </div>

        <div class="formula-box">
            <strong>Formula:</strong><br>
            Pk = Value at position (k/100) √ó (n+1)<br>
            where k is the percentile (1-99) and n is sample size
        </div>

        <div class="simple-explanation">
            <strong>Simple Explanation:</strong> If you scored in the 90th percentile on a test,
            you did better than 90% of all test takers.
        </div>
        """, unsafe_allow_html=True)

        # Interactive percentile calculator
        st.subheader("üßÆ Interactive Percentile Calculator")

        col1, col2 = st.columns(2)

        with col1:
            percentile_value = st.slider("Select percentile:", 1, 99, 50)
            calculated_percentile = np.percentile(data, percentile_value)

            st.metric(f"{percentile_value}th Percentile", f"{calculated_percentile:.2f}")
            st.write(f"**Meaning:** {percentile_value}% of values are below {calculated_percentile:.2f}")

            # Common percentiles
            st.markdown("**Common Percentiles:**")
            common_percentiles = [10, 25, 50, 75, 90, 95, 99]
            for p in common_percentiles:
                value = np.percentile(data, p)
                st.write(f"P{p}: {value:.2f}")

        with col2:
            fig, ax = plt.subplots(figsize=(8, 5))
            ax.hist(data, bins=30, alpha=0.7, color='lightgreen', edgecolor='black')
            ax.axvline(calculated_percentile, color='red', linestyle='--', linewidth=3,
                      label=f'P{percentile_value}: {calculated_percentile:.2f}')

            ax.set_title(f'Distribution with {percentile_value}th Percentile')
            ax.set_xlabel('Values')
            ax.set_ylabel('Frequency')
            ax.legend()
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)

    # Practical applications summary
    st.markdown("## üéØ Real-World Applications Summary")

    applications = {
        "Education": {
            "Percentiles": "SAT/GRE scores, class rankings",
            "Quartiles": "Grade distribution analysis",
            "Impact": "College admissions, scholarship decisions"
        },
        "Healthcare": {
            "Percentiles": "Growth charts for children, BMI categories",
            "Quartiles": "Blood pressure ranges, diagnostic thresholds",
            "Impact": "Early intervention, treatment protocols"
        },
        "Finance": {
            "Quintiles": "Investment risk categories, credit scores",
            "Deciles": "Wealth distribution analysis",
            "Impact": "Portfolio management, loan approvals"
        },
        "Business": {
            "Quartiles": "Customer segmentation, performance evaluation",
            "Percentiles": "Salary benchmarking, KPI tracking",
            "Impact": "Strategic planning, resource allocation"
        }
    }

    for sector, info in applications.items():
        with st.expander(f"üè¢ {sector}"):
            for measure, description in info.items():
                if measure != "Impact":
                    st.write(f"**{measure}:** {description}")
            st.write(f"**üíº Business Impact:** {info['Impact']}")

def show_terminology():
    st.markdown('<h1 class="main-header">üìö Statistical Terminology</h1>', unsafe_allow_html=True)

    if st.button("üè† Back to Home", key="back_terminology"):
        st.session_state.current_section = 'home'
        st.rerun()

    st.markdown("""
    ## Complete Statistical Reference Guide

    Master statistical concepts with definitions, formulas, and simple explanations.
    """)

    # Organize terms by category
    terminology_categories = {
        "üìä Descriptive Statistics": {
            "Mean (Average)": {
                "formula": "Œº = Œ£x / n",
                "definition": "The sum of all values divided by the number of values. Most common measure of central tendency.",
                "simple": "Add all numbers and divide by how many numbers you have. Like finding the average test score.",
                "example": "Test scores: 85, 90, 88, 92, 85. Mean = (85+90+88+92+85)/5 = 88"
            },
            "Median": {
                "formula": "Middle value when data is ordered",
                "definition": "The middle value in a dataset when arranged in ascending order. Divides data into two equal halves.",
                "simple": "Line up all numbers from smallest to largest and pick the middle one.",
                "example": "Values: 10, 15, 20, 25, 30. Median = 20 (middle value)"
            },
            "Mode": {
                "formula": "Most frequently occurring value",
                "definition": "The value that appears most often in a dataset. A dataset can have no mode, one mode, or multiple modes.",
                "simple": "The number that shows up most often in your list.",
                "example": "Shoe sizes: 7, 8, 8, 9, 8, 10. Mode = 8 (appears 3 times)"
            },
            "Standard Deviation": {
                "formula": "œÉ = ‚àö(Œ£(x - Œº)¬≤ / N)",
                "definition": "Measures the average distance of data points from the mean. Shows how spread out the data is.",
                "simple": "Tells you how much your numbers typically differ from the average.",
                "example": "Low SD = numbers close to average. High SD = numbers spread out from average."
            },
            "Variance": {
                "formula": "œÉ¬≤ = Œ£(x - Œº)¬≤ / N",
                "definition": "The average of squared differences from the mean. Variance is the square of standard deviation.",
                "simple": "Like standard deviation but squared. Shows how much data varies from the average.",
                "example": "If SD = 5, then Variance = 25. Units are squared (e.g., dollars¬≤)."
            },
            "Range": {
                "formula": "Range = Maximum - Minimum",
                "definition": "The difference between the largest and smallest values in a dataset.",
                "simple": "Subtract the smallest number from the biggest number.",
                "example": "Test scores: 65, 78, 85, 92, 98. Range = 98 - 65 = 33"
            },
            "Interquartile Range (IQR)": {
                "formula": "IQR = Q3 - Q1",
                "definition": "The range of the middle 50% of data. Difference between 75th and 25th percentiles.",
                "simple": "The spread of the middle half of your data, ignoring extreme values.",
                "example": "Q1 = 25, Q3 = 75. IQR = 75 - 25 = 50"
            },
            "Coefficient of Variation": {
                "formula": "CV = (œÉ / Œº) √ó 100%",
                "definition": "Standard deviation expressed as a percentage of the mean. Allows comparison across different scales.",
                "simple": "Compares variability relative to the average. Useful for comparing different datasets.",
                "example": "Stock A: Mean=$50, SD=$5, CV=10%. Stock B: Mean=$100, SD=$8, CV=8%"
            }
        },
        "üìà Distribution Properties": {
            "Skewness": {
                "formula": "Skewness = E[(X-Œº)¬≥] / œÉ¬≥",
                "definition": "Measures the asymmetry of a distribution. Indicates which tail is longer.",
                "simple": "Shows if your data leans more to one side. Like a lopsided hill.",
                "example": "Positive skew = tail on right (income data). Negative skew = tail on left (test scores)"
            },
            "Kurtosis": {
                "formula": "Kurtosis = E[(X-Œº)‚Å¥] / œÉ‚Å¥ - 3",
                "definition": "Measures the 'tailedness' of a distribution. Indicates presence of outliers.",
                "simple": "Shows if your data has heavy tails (more extreme values) or light tails.",
                "example": "High kurtosis = more outliers. Low kurtosis = fewer extreme values."
            },
            "Normal Distribution": {
                "formula": "f(x) = (1/œÉ‚àö2œÄ) √ó e^(-¬Ω((x-Œº)/œÉ)¬≤)",
                "definition": "A symmetric, bell-shaped distribution where mean = median = mode. 68-95-99.7 rule applies.",
                "simple": "The classic bell curve. Most values cluster around the middle.",
                "example": "Heights, test scores, measurement errors often follow normal distribution."
            },
            "Standard Normal Distribution": {
                "formula": "Z = (X - Œº) / œÉ",
                "definition": "Normal distribution with mean = 0 and standard deviation = 1. Used for standardization.",
                "simple": "Converting any normal distribution to a standard scale for comparison.",
                "example": "Z-score of 1.5 means 1.5 standard deviations above average."
            }
        },
        "üìä Percentiles & Quantiles": {
            "Percentile": {
                "formula": "Pk = value below which k% of data falls",
                "definition": "Values that divide data into 100 equal parts. The kth percentile has k% of data below it.",
                "simple": "Your position compared to everyone else, expressed as a percentage.",
                "example": "90th percentile = you scored better than 90% of people."
            },
            "Quartile": {
                "formula": "Q1=P25, Q2=P50, Q3=P75",
                "definition": "Values that divide data into four equal parts (25% each).",
                "simple": "Splits your data into four equal groups.",
                "example": "Q1: bottom 25%, Q2: median, Q3: top 25% boundary"
            },
            "Decile": {
                "formula": "Di = P(i√ó10)",
                "definition": "Values that divide data into ten equal parts (10% each).",
                "simple": "Splits your data into ten equal groups.",
                "example": "D1 = 10th percentile, D5 = 50th percentile"
            },
            "Quintile": {
                "formula": "Qi = P(i√ó20)",
                "definition": "Values that divide data into five equal parts (20% each).",
                "simple": "Splits your data into five equal groups.",
                "example": "Used in investment risk categories, income brackets"
            }
        },
        "üîó Correlation & Relationships": {
            "Correlation Coefficient": {
                "formula": "r = Œ£[(xi-xÃÑ)(yi-»≥)] / ‚àö[Œ£(xi-xÃÑ)¬≤Œ£(yi-»≥)¬≤]",
                "definition": "Measures the strength and direction of linear relationship between two variables (-1 to +1).",
                "simple": "Shows how two things move together. +1 = perfect positive, -1 = perfect negative, 0 = no relationship.",
                "example": "Height vs Weight: r = 0.7 (strong positive). Study time vs TV time: r = -0.5 (moderate negative)"
            },
            "Coefficient of Determination (R¬≤)": {
                "formula": "R¬≤ = r¬≤",
                "definition": "Proportion of variance in dependent variable explained by independent variable(s).",
                "simple": "Percentage of variation in Y that's explained by X.",
                "example": "R¬≤ = 0.64 means 64% of variation in test scores is explained by study hours."
            },
            "Covariance": {
                "formula": "Cov(X,Y) = E[(X-Œºx)(Y-Œºy)]",
                "definition": "Measures how two variables vary together. Indicates direction but not strength of relationship.",
                "simple": "Shows if two variables move in same direction (positive) or opposite (negative).",
                "example": "Positive covariance: both increase together. Negative: one increases as other decreases."
            }
        },
        "üìè Sampling & Inference": {
            "Population": {
                "formula": "N = total population size",
                "definition": "The entire group of individuals or items that we want to study or draw conclusions about.",
                "simple": "Everyone or everything you're interested in studying.",
                "example": "All students in a university, all voters in a country, all products made by a factory."
            },
            "Sample": {
                "formula": "n = sample size",
                "definition": "A subset of the population selected for study. Should be representative of the population.",
                "simple": "A smaller group chosen to represent the whole population.",
                "example": "Surveying 1,000 voters to predict election results for millions of voters."
            },
            "Sample Size": {
                "formula": "n = (Z¬≤œÉ¬≤) / E¬≤",
                "definition": "The number of observations in a sample. Larger samples generally provide more reliable results.",
                "simple": "How many people or things you include in your study.",
                "example": "Survey of 500 people vs 50 people - the 500 is more reliable."
            },
            "Confidence Interval": {
                "formula": "CI = xÃÑ ¬± (t √ó SE)",
                "definition": "A range of values that likely contains the true population parameter with specified confidence.",
                "simple": "A range where we're pretty sure the true answer lies.",
                "example": "95% confident the average height is between 5'6\" and 5'10\""
            },
            "Margin of Error": {
                "formula": "ME = Z √ó (œÉ / ‚àön)",
                "definition": "The maximum expected difference between sample statistic and true population parameter.",
                "simple": "How far off our estimate might be from the true value.",
                "example": "Poll shows 52% support ¬±3% margin of error = true support is 49-55%"
            },
            "Standard Error": {
                "formula": "SE = œÉ / ‚àön",
                "definition": "Standard deviation of the sampling distribution. Measures precision of sample statistic.",
                "simple": "Shows how much your sample average might vary from the true average.",
                "example": "Smaller standard error = more precise estimate"
            }
        },
        "üß™ Hypothesis Testing": {
            "Null Hypothesis (H‚ÇÄ)": {
                "formula": "H‚ÇÄ: parameter = specified value",
                "definition": "A statement of no effect or no difference. Assumes status quo until proven otherwise.",
                "simple": "The 'nothing special is happening' assumption we try to disprove.",
                "example": "H‚ÇÄ: New drug has no effect (same as placebo)"
            },
            "Alternative Hypothesis (H‚ÇÅ)": {
                "formula": "H‚ÇÅ: parameter ‚â† specified value",
                "definition": "A statement that contradicts the null hypothesis. What we want to prove.",
                "simple": "The 'something interesting is happening' claim we're testing.",
                "example": "H‚ÇÅ: New drug is more effective than placebo"
            },
            "P-value": {
                "formula": "P(observing data | H‚ÇÄ is true)",
                "definition": "Probability of observing the data (or more extreme) if null hypothesis is true.",
                "simple": "How surprising your results would be if nothing special was happening.",
                "example": "p = 0.03 means 3% chance of these results if null hypothesis is true"
            },
            "Significance Level (Œ±)": {
                "formula": "Œ± = 0.05 (common choice)",
                "definition": "Threshold for rejecting null hypothesis. Probability of Type I error.",
                "simple": "How sure you need to be before saying you found something significant.",
                "example": "Œ± = 0.05 means you accept 5% chance of being wrong"
            },
            "Type I Error": {
                "formula": "P(reject H‚ÇÄ | H‚ÇÄ is true) = Œ±",
                "definition": "Rejecting a true null hypothesis. False positive.",
                "simple": "Thinking you found something when you really didn't.",
                "example": "Concluding drug works when it actually doesn't"
            },
            "Type II Error": {
                "formula": "P(accept H‚ÇÄ | H‚ÇÅ is true) = Œ≤",
                "definition": "Accepting a false null hypothesis. False negative.",
                "simple": "Missing a real effect when it actually exists.",
                "example": "Concluding drug doesn't work when it actually does"
            },
            "Statistical Power": {
                "formula": "Power = 1 - Œ≤",
                "definition": "Probability of correctly rejecting a false null hypothesis.",
                "simple": "Your ability to detect a real effect when it exists.",
                "example": "80% power means 80% chance of finding effect if it's really there"
            }
        }
    }

    # Create expandable sections for each category
    for category, terms in terminology_categories.items():
        with st.expander(f"{category} ({len(terms)} terms)"):
            for term, info in terms.items():
                st.markdown(f"### üìñ {term}")

                col1, col2 = st.columns(2)

                with col1:
                    st.markdown(f"""
                    <div class="formula-box">
                        <strong>Formula:</strong> {info['formula']}
                    </div>

                    <div class="definition-box">
                        <strong>Technical Definition:</strong> {info['definition']}
                    </div>
                    """, unsafe_allow_html=True)

                with col2:
                    st.markdown(f"""
                    <div class="simple-explanation">
                        <strong>Simple Explanation:</strong> {info['simple']}
                    </div>

                    **Example:** {info['example']}
                    """)

                st.markdown("---")

    # Quick reference search
    st.markdown("## üîç Quick Term Search")

    search_term = st.text_input("Search for a statistical term:", placeholder="e.g., mean, correlation, p-value")

    if search_term:
        found_terms = []
        search_lower = search_term.lower()

        for category, terms in terminology_categories.items():
            for term, info in terms.items():
                if (search_lower in term.lower() or
                    search_lower in info['definition'].lower() or
                    search_lower in info['simple'].lower()):
                    found_terms.append((category, term, info))

        if found_terms:
            st.markdown(f"### Found {len(found_terms)} result(s):")
            for category, term, info in found_terms:
                st.markdown(f"""
                **{term}** ({category})
                - **Definition:** {info['definition']}
                - **Simple:** {info['simple']}
                - **Formula:** {info['formula']}
                """)
        else:
            st.write("No terms found. Try different keywords.")

    # Statistical symbols reference
    st.markdown("## üî£ Common Statistical Symbols")

    symbols = {
        "Greek Letters": {
            "Œº (mu)": "Population mean",
            "œÉ (sigma)": "Population standard deviation",
            "œÉ¬≤ (sigma squared)": "Population variance",
            "Œ± (alpha)": "Significance level, Type I error rate",
            "Œ≤ (beta)": "Type II error rate",
            "œÅ (rho)": "Population correlation coefficient",
            "œá¬≤ (chi-squared)": "Chi-square statistic"
        },
        "Latin Letters": {
            "xÃÑ (x-bar)": "Sample mean",
            "s": "Sample standard deviation",
            "s¬≤": "Sample variance",
            "n": "Sample size",
            "N": "Population size",
            "r": "Sample correlation coefficient",
            "p": "Probability, proportion"
        },
        "Other Symbols": {
            "H‚ÇÄ": "Null hypothesis",
            "H‚ÇÅ or H‚Çê": "Alternative hypothesis",
            "‚â†": "Not equal to",
            "‚â§": "Less than or equal to",
            "‚â•": "Greater than or equal to",
            "Œ£": "Sum of",
            "‚àö": "Square root",
            "‚àû": "Infinity"
        }
    }

    symbol_cols = st.columns(3)

    for i, (category, symbol_dict) in enumerate(symbols.items()):
        with symbol_cols[i]:
            st.markdown(f"**{category}**")
            for symbol, meaning in symbol_dict.items():
                st.write(f"**{symbol}:** {meaning}")

def show_feedback_form():
    st.markdown('<h1 class="main-header">üí¨ Feedback & Suggestions</h1>', unsafe_allow_html=True)

    if st.button("üè† Back to Home", key="back_feedback"):
        st.session_state.current_section = 'home'
        st.rerun()

    st.markdown("""
    ## Help Us Improve! üöÄ

    Your feedback is invaluable in making this statistics learning platform better.
    Please share your thoughts, suggestions, and ideas for future versions.
    """)

    # Feedback form
    with st.form("feedback_form", clear_on_submit=True):
        st.subheader("üìù Your Feedback")

        # User information (optional)
        col1, col2 = st.columns(2)
        with col1:
            name = st.text_input("Name (Optional)", placeholder="Your name")
        with col2:
            email = st.text_input("Email (Optional)", placeholder="your.email@example.com")

        # Feedback category
        feedback_category = st.selectbox(
            "Feedback Category",
            ["General Feedback", "Bug Report", "Feature Request", "Content Suggestion",
             "User Interface", "Performance Issue", "Educational Content", "Other"]
        )

        # Rating
        st.subheader("‚≠ê Rate Your Experience")
        overall_rating = st.select_slider(
            "Overall satisfaction with the platform:",
            options=[1, 2, 3, 4, 5],
            format_func=lambda x: "‚≠ê" * x,
            value=4
        )

        # Specific ratings
        col1, col2 = st.columns(2)
        with col1:
            ease_of_use = st.select_slider(
                "Ease of use:",
                options=[1, 2, 3, 4, 5],
                format_func=lambda x: "‚≠ê" * x,
                value=4
            )
        with col2:
            content_quality = st.select_slider(
                "Content quality:",
                options=[1, 2, 3, 4, 5],
                format_func=lambda x: "‚≠ê" * x,
                value=4
            )

        # What did you like most?
        liked_most = st.text_area(
            "What did you like most about the platform?",
            placeholder="Tell us what worked well for you..."
        )

        # What could be improved?
        improvements = st.text_area(
            "What could be improved?",
            placeholder="Share your suggestions for improvement..."
        )

        # Feature requests
        feature_requests = st.text_area(
            "Any features you'd like to see in future versions?",
            placeholder="Describe new features or enhancements you'd like..."
        )

        # Additional comments
        additional_comments = st.text_area(
            "Additional comments:",
            placeholder="Any other thoughts or suggestions..."
        )

        # Learning background
        st.subheader("üìö About Your Background")

        col1, col2 = st.columns(2)
        with col1:
            statistics_level = st.selectbox(
                "Your statistics knowledge level:",
                ["Beginner", "Intermediate", "Advanced", "Expert"]
            )
        with col2:
            primary_use = st.selectbox(
                "Primary use case:",
                ["Learning/Education", "Work/Professional", "Research", "Teaching", "Personal Interest"]
            )

        # Specific section feedback
        st.subheader("üìä Section-Specific Feedback")

        sections_used = st.multiselect(
            "Which sections did you use?",
            ["Data Types Explorer", "Central Tendency", "Dispersion Measures",
             "Univariate Analysis", "Bivariate Analysis", "Quantiles & Percentiles",
             "Statistical Terminology"]
        )

        if sections_used:
            most_helpful = st.selectbox(
                "Which section was most helpful?",
                sections_used
            )

            least_helpful = st.selectbox(
                "Which section needs the most improvement?",
                sections_used + ["None - all were great!"]
            )

        # Submit button
        submitted = st.form_submit_button("üöÄ Submit Feedback", use_container_width=True)

        if submitted:
            # Display thank you message
            st.success("üéâ Thank you for your feedback!")
            st.balloons()

            # In a real application, this would save to a database
            feedback_data = {
                "name": name,
                "email": email,
                "category": feedback_category,
                "overall_rating": overall_rating,
                "ease_of_use": ease_of_use,
                "content_quality": content_quality,
                "liked_most": liked_most,
                "improvements": improvements,
                "feature_requests": feature_requests,
                "additional_comments": additional_comments,
                "statistics_level": statistics_level,
                "primary_use": primary_use,
                "sections_used": sections_used,
                "most_helpful": most_helpful if sections_used else None,
                "least_helpful": least_helpful if sections_used else None,
                "timestamp": pd.Timestamp.now()
            }

            st.markdown("### üìã Your Feedback Summary:")
            st.json(feedback_data)

            st.markdown("""
            **What happens next?**
            - Your feedback will be reviewed by our development team
            - We'll use your suggestions to prioritize improvements
            - If you provided your email, we may follow up with questions
            - Check back for updates in future versions!
            """)

    # Feedback statistics and trends
    st.markdown("---")
    st.subheader("üìä Community Feedback Trends")

    # Mock feedback statistics (in real app, this would come from database)
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("Total Feedback", "1,247", delta="32 this week")
    with col2:
        st.metric("Average Rating", "4.2/5", delta="0.1")
    with col3:
        st.metric("Response Rate", "78%", delta="5%")
    with col4:
        st.metric("Feature Requests", "89", delta="12 new")

    # Most requested features
    st.markdown("### üéØ Most Requested Features")

    requested_features = {
        "More Interactive Exercises": 89,
        "Video Tutorials": 67,
        "Advanced Statistical Tests": 54,
        "Mobile App Version": 43,
        "Collaborative Features": 38,
        "API for Data Integration": 32,
        "Offline Mode": 28,
        "Multi-language Support": 25
    }

    feature_df = pd.DataFrame(list(requested_features.items()),
                             columns=['Feature', 'Requests'])

    fig, ax = plt.subplots(figsize=(10, 6))
    bars = ax.barh(feature_df['Feature'], feature_df['Requests'], color='lightblue')
    ax.set_xlabel('Number of Requests')
    ax.set_title('Most Requested Features')
    ax.grid(True, alpha=0.3)

    # Add value labels
    for i, bar in enumerate(bars):
        width = bar.get_width()
        ax.text(width + 1, bar.get_y() + bar.get_height()/2,
                f'{int(width)}', ha='left', va='center')

    plt.tight_layout()
    st.pyplot(fig)

    # Contact information
    st.markdown("---")
    st.subheader("üìû Other Ways to Reach Us")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("""
        **üìß Email Support**
        - General: support@statisticshub.com
        - Technical: tech@statisticshub.com
        - Feature Requests: features@statisticshub.com
        """)

    with col2:
        st.markdown("""
        **üí¨ Community**
        - GitHub Issues: github.com/statshub
        - Discord Server: discord.gg/statshub
        - Reddit: r/StatisticsHub
        """)

    with col3:
        st.markdown("""
        **üì± Social Media**
        - Twitter: @StatisticsHub
        - LinkedIn: Statistics Hub
        - YouTube: Statistics Hub Channel
        """)

    # Version information
    st.markdown("---")
    st.markdown("""
    **Current Version:** v2.1.0
    **Last Updated:** August 2025
    **Next Release:** September 2025 (planned)
    """)

def show_descriptive_stats():
    st.markdown('<h1 class="main-header">üìà Descriptive Statistics Overview</h1>', unsafe_allow_html=True)

    if st.button("üè† Back to Home", key="back_descriptive"):
        st.session_state.current_section = 'home'
        st.rerun()

    datasets = load_sample_datasets()

    # Dataset selection
    dataset_choice = st.selectbox("Choose a dataset:", list(datasets.keys()))
    selected_data = datasets[dataset_choice]

    # Display basic information
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Dataset Overview")
        st.write(f"**Shape:** {selected_data.shape}")
        st.write(f"**Columns:** {list(selected_data.columns)}")

    with col2:
        st.subheader("Sample Data")
        st.dataframe(selected_data.head())

    # Select numeric column for analysis
    numeric_cols = selected_data.select_dtypes(include=[np.number]).columns.tolist()
    if numeric_cols:
        selected_column = st.selectbox("Select a numeric column for analysis:", numeric_cols)

        if selected_column:
            data = selected_data[selected_column].dropna()
            if len(data) > 0:
                stats_dict = calculate_statistics(data)

                if stats_dict:
                    # Display statistics in metrics
                    st.subheader("üìä Descriptive Statistics")

                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("Mean", f"{stats_dict['mean']:.2f}")
                        st.metric("Standard Deviation", f"{stats_dict['std']:.2f}")
                    with col2:
                        st.metric("Median", f"{stats_dict['median']:.2f}")
                        st.metric("Variance", f"{stats_dict['var']:.2f}")
                    with col3:
                        st.metric("Mode", f"{stats_dict['mode']:.2f}")
                        st.metric("Range", f"{stats_dict['range']:.2f}")
                    with col4:
                        st.metric("Q1", f"{stats_dict['q1']:.2f}")
                        st.metric("Q3", f"{stats_dict['q3']:.2f}")

                    # Visualizations
                    st.subheader("üìà Visualizations")

                    # Create tabs for different visualizations
                    tab1, tab2, tab3, tab4 = st.tabs(["Histogram", "Box Plot", "Distribution", "Summary"])

                    with tab1:
                        bins = st.slider("Number of bins:", 10, 50, 30)
                        fig, ax = plt.subplots(figsize=(10, 6))
                        ax.hist(data, bins=bins, alpha=0.7, color='skyblue', edgecolor='black')
                        ax.set_title(f'Histogram of {selected_column}')
                        ax.set_xlabel(selected_column)
                        ax.set_ylabel('Frequency')
                        st.pyplot(fig)

                    with tab2:
                        fig, ax = plt.subplots(figsize=(10, 6))
                        ax.boxplot(data)
                        ax.set_title(f'Box Plot of {selected_column}')
                        ax.set_ylabel(selected_column)
                        st.pyplot(fig)

                    with tab3:
                        fig, ax = plt.subplots(figsize=(10, 6))
                        sns.histplot(data, kde=True, ax=ax)
                        ax.set_title(f'Distribution of {selected_column}')
                        st.pyplot(fig)

                    with tab4:
                        st.write(selected_data.describe())

if __name__ == "__main__":
    main()















